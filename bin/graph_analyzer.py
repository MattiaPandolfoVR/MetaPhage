# Coded by Gioele Lazzari (gioele.lazza@studenti.univr.it)
software = "graph_analyzer.py"
version = "0.9.2"

import sys, os, io, argparse, logging, textwrap
from operator import itemgetter
from copy import deepcopy


#############
# ARGPARSER #
#############

parser = argparse.ArgumentParser(
    description = "This script is designed to extract the most probable taxonomic "
                  "assignation from the genome_by_genome_overview.csv and c1.ntw files "
                  "generated by vConTACT2. In fact, on bitbucket.org/MAVERICLab/vcontact2/ "
                  "at date 21-09-2020, it's possible to read what follows: \n\n"
                  "<< One important note is that the taxonomic information is not included "
                  "for user sequences. This means that each user will need to find their "
                  "genome(s) of interest and check to see if reference genomes are located "
                  "in the same VC. If the user genome is within the same VC subcluster as a "
                  "reference genome, then there's a very high probability that the user "
                  "genome is part of the same genus. If the user genome is in the same VC "
                  "but not the same subcluster as a reference, then it's highly likely the two "
                  "genomes are related at roughly genus-subfamily level. If there are no "
                  "reference genomes in the same VC or VC subcluster, then it's likely that "
                  "they are not related at the genus level at all. That said, it is possible "
                  "they could be related at a higher taxonomic level (subfamily, family, order). >>\n\n",
    formatter_class = argparse.RawTextHelpFormatter)

options = parser.add_argument_group("Options")

options.add_argument('-v', '--version', action='version', version= software + " v" + version)

options.add_argument('-g', '--input-graph', dest='input_graph', metavar='FILENAME', default='c1.ntw')
options.add_argument('-c', '--input-csv', dest='input_csv', metavar='FILENAME', default='genome_by_genome_overview.csv')
options.add_argument('-m', '--input-metas', dest='input_metas', metavar='FILENAME', default=None)
options.add_argument('-o', '--output', dest='output_path', metavar='PATH', default='./')
options.add_argument('-p', '--suffix', dest='string_suffix', metavar='STRING', default='sample')


######################
# EXTERNAL LIBRARIES #
######################

def error(msg):
    sys.stderr.write("ERROR: {}\n".format(msg))
    sys.stderr.flush()
    sys.exit(1)

try:
    import pandas as pnd 
except ImportError:
    error("The pandas library was not found.")

try:
    import networkx as net # net.spring_layout() could require also scipy
except ImportError:
    error("The networkx or scipy library was not found.")

try: 
    from networkx.drawing.nx_agraph import graphviz_layout
    # Mac: conda install graphviz==2.42.3=h055b950_2 -c conda-forge
    # Mac: conda install pygraphviz==1.6=py37hd4be98e_1 -c conda-forge
except ImportError:
    error("The pygraphviz library was not found.") 

try:
    import hvplot.networkx as hvnx
    import hvplot.pandas # hvPlot dynamically adds the Pandas .hvplot() method
    import hvplot # for the save() method
    from bokeh.resources import INLINE # for viewing html pages also without an internet connection
except ImportError:
    error("The hvplot library was not found.")

try:
    import panel as pnl
    pnl.extension() # before displaying anything with Panel it is always necessary to load the Panel extension
except ImportError:
    error("The panel library was not found.")


##################
# CORE FUNCTIONS #
##################

def clusterExtractor(g, df, output_path, string_suffix):

    # prepare results dataframe
    results = pnd.DataFrame(data = {
        'Scaffold': [],
        'Closer': [],
        'Accession': [],
        'Status': [],
        'VC': [],
        'Level': [],
        'Weight': [],
        'Host': [],
        'Genus': [],
        'Family': []#,
        #'Order': [],
        #'Class': [],
        #'Phylum': [],
        #'Kingdom': [],
        #'Realm': [],
        })


    def insertReference(df, results, scaffold, closer, weight, level, status, vc):

        # extract taxonomy
        species = "n.a."
        genus = "n.a."
        family = "n.a."
        #order = "n.a."
        #classs = "n.a."
        #phylum = "n.a."
        #kingdom = "n.a."
        #realm = "n.a."

        # extract other infos
        host = "n.a."

        # "G": not in the graph
        # "F": present in the graph but not assigned
        if level != "F" and level != "G":
            
            species = df.loc[df['Genome'] == closer, 'Species'].values[0]
            genus = df.loc[df['Genome'] == closer, 'Genus'].values[0]
            family = df.loc[df['Genome'] == closer, 'Family'].values[0]
            #order = df.loc[df['Genome'] == closer, 'Order'].values[0]
            #classs = df.loc[df['Genome'] == closer, 'Class'].values[0]
            #phylum = df.loc[df['Genome'] == closer, 'Phylum'].values[0]
            #kingdom = df.loc[df['Genome'] == closer, 'Kingdom'].values[0]
            #realm = df.loc[df['Genome'] == closer, 'Realm'].values[0]

            host = df.loc[df['Genome'] == closer, 'Host'].values[0]
        
        # format weight (cloud be float or "n.a.")
        if type(weight) != str:
            weight = str(int(round(weight,0))) 

        # append new row:
        results = results.append({
            'Scaffold': scaffold,
            'Closer': species,
            'Accession': closer,
            'Status': status,
            'VC': vc,
            'Level': level,
            'Weight': weight,
            'Host': host,
            'Genus': genus,
            'Family': family#,
            #'Order': order,
            #'Class': classs,
            #'Phylum': phylum,
            #'Kingdom': kingdom,
            #'Realm': realm,
            }, ignore_index = True) 

        return results


    ####################
    # PREPARATORY PART #
    ####################

    # create the .log file
    logging.basicConfig(filename = output_path + 'graph_analyzer_' + string_suffix + '.log', filemode='w', level = logging.INFO, # level sets the threshold
                        format = '%(asctime)s %(levelname)s: %(message)s',
                        datefmt = '%H:%M:%S') 
    logging.info('Processing of vConTACT2 output is started.\n')

    # less problematic when called as variable
    df = df.rename(columns={"VC Subcluster": "VCSubcluster"})
    df = df.rename(columns={"VC Status": "VCStatus"})

    # sobstitute NA with '' to avoid future runtime errors
    df = df.fillna('')

    # make a copy of the original df
    df_copy = df.copy(deep = True)

    # add a column that is a copy of "Genome": it will be updated at every iteration of the algorithm
    df_copy['Genome_editable'] = df['Genome']

    # make a copy of the original graph: this will contain an editable flag for each scaffold node
    g_copy = deepcopy(g)
    for node in g_copy.nodes: # create an "assignment" attribute for all nodes
        net.set_node_attributes(g_copy, {node: node}, "assignment") # store a copy of node's name

    ###################
    # PROCESSING PART #
    ###################

    # extract scaffolds from reference genomes
    scaffolds_total = df_copy[df_copy['Genome_editable'].str.contains('NODE_')]

    # extract scaffolds contained in the graph 
    scaffolds_ingraph = scaffolds_total.copy(deep = True)
    for row in scaffolds_ingraph.itertuples():
        if g_copy.has_node(row.Genome) == False : 
            # remove row if scaffold is not in the graph
            scaffolds_ingraph = scaffolds_ingraph.drop(scaffolds_ingraph[scaffolds_ingraph.Genome == row.Genome].index)
            # append in results as level="G"(NOT IN GRAPH)
            status = row.VCStatus # COULD BE a "Singleton", never present in the graph
            results = insertReference(df=df, results=results, scaffold=row.Genome, closer="n.a.", weight="n.a.", level="G", status=status, vc="n.a.")

    # log first stats                
    logging.info("Viral scaffolds in total: %i" % len(scaffolds_total))
    logging.info("Viral scaffolds in the graph: %i\n" % len(scaffolds_ingraph))


    # to count how many iterations the algorithm does
    counter_iterations = 0

    # to count how many new assignments at every iteration
    counter_new = -1 # -1 is just to start the algorithm
    while(counter_new != 0):

        counter_new = 0 # reset the counter at every iteration
        counter_iterations += 1
        logging.info("##############################################")
        logging.info("################ Iteration %i #################" % counter_iterations)
        logging.info("##############################################\n")

        
        # for each viral scaffold in the graph:
        for row in scaffolds_ingraph.itertuples():
            
            # skip already assigned scaffolds:
            # assigned scaffold:     {NODE_...}{Staphylococcus...}
            # NOT assigned scaffold: {NODE_...}{NODE_...}
            if not "NODE_" in row.Genome_editable:
                continue
            
            # extract scaffold name and VCStatus
            scaffold = row.Genome
            status = row.VCStatus
            logging.info("Scaffold: %s" % (scaffold))
            logging.info("VCStatus: %s" % (status))
              
            # COMPUTE NEIGHBORS
            neighbors_list = list(g_copy.neighbors(scaffold))
            logging.info("Neighbors: %i" % len(neighbors_list))
            

            if (status == "Clustered" or status == "Outlier" or status == "Clustered/Singleton" or "Overlap" in status):
                
                vc = "" # scaffold's viral cluster or subcluster
                sameclustered_list = [] # other genomes/scaffolds in the same cluster/subcluster
                
                # EXTRACT SAMECLUSTERED LIST:
                logging.info("Extracting sameclustered (sc)...")
                if status == "Clustered":

                    vc = row.VCSubcluster
                    # extract all scaffolds clustered in the same subcluster (hereafter: the sameclustered)
                    sameclustered = df_copy[df_copy['VCSubcluster'].str.contains(vc)]
                    # remove current scaffold's row
                    sameclustered = sameclustered.drop(sameclustered[sameclustered.Genome == scaffold].index)
                    sameclustered_list = sameclustered["Genome"].tolist()
                
                elif status == "Outlier": # not clustered but connected

                    vc = "n.a."
                    sameclustered_list = []

                elif status == "Clustered/Singleton": # they have a subcluster of their own
                    
                    # extract all the possible subclusteres within the cluster
                    vc = "VC_" + row.VCSubcluster.split("_")[1]
                    sameclustered = df_copy[df_copy['VCSubcluster'].str.contains(vc)]
                    # remove current scaffold's row
                    sameclustered = sameclustered.drop(sameclustered[sameclustered.Genome == scaffold].index)
                    sameclustered_list = sameclustered["Genome"].tolist()

                elif "Overlap" in status: # "Overlap" belong to n cluster

                    # extract the n cluster and consider every of thier subcluster
                    vc_list = status.replace("Overlap (", "").replace(")", "").split("/")
                    sameclustered = pnd.DataFrame() # empty df
                    for vc in vc_list: # extract the rows and glue them the the previous
                        sameclustered = sameclustered.append(df_copy[df_copy['VCSubcluster'].str.contains(vc)])
                    # remove current scaffold's row
                    sameclustered = sameclustered.drop(sameclustered[sameclustered.Genome == scaffold].index)
                    sameclustered_list = sameclustered["Genome"].tolist()


                # log some stats
                logging.info("Number of sc: %i" % len(sameclustered_list))
                # check if all sameclustered are contained in the neighbours
                logging.info("Are all sc connected to scaffold?: %s" % set(sameclustered_list).issubset(neighbors_list))

                
                # GET SAMECLUSTERED-CONNECTED LIST ORDERED BY WEIGHT
                # associate every CONNECTED sameclustered with its weight
                logging.info("Extracting sc-connected (scc)...")
                connected_list = [] # this will be a list of DICT:
                # {"scaffold": ___, "weight": ___, "assignment": ___}
                for node in sameclustered_list:
                    try: 
                        w = g_copy.get_edge_data(scaffold, node)["weight"]
                        assignment = g_copy.nodes[node]['assignment']
                        connected_list.append({"scaffold": node, "weight": w, "assignment": assignment})
                    except: # not every pair of nodes in the same cluster are directly connected in the graph
                        continue
                # ordinate the list by weight (itemgetter is from the operator library)
                connected_list = sorted(connected_list, key=itemgetter('weight'), reverse=True) # reverse for descending order


                # EXTRACT 'CLOSER_NODE' (= the haviest connected-sameclustered)
                # note that closer_node could be another scaffold!
                try: 
                    closer_node = connected_list[0]["scaffold"] # to store the node connected with the heavier edge
                    closer_node_w = connected_list[0]["weight"] # to store the heavier edge
                except: # not always there is a best_bet: for example "Outlier" are not clustered
                    closer_node = "n.a."
                    closer_node_w = 0.0 
                logging.info("closer_node: %s" % closer_node)
                logging.info("closer_node_w: %f" % closer_node_w)

                
                # 'CLOSER_REF' SEARCH
                closer_ref = "n.a." # store the reference genome connected with the heavier edge
                closer_ref_w = 0.0 # store the heavier egde that connect to a reference genome
                level = "n.a." # keep track of the cardinality (order of the list)

                # iterate the list until the first reference genome is reached
                for i in range(len(connected_list)):
                    # if it's connected a true reference genome or a scaffold assigned in the last iteration:
                    if  connected_list[i]["scaffold"].find("NODE_") == -1 or connected_list[i]["assignment"].find("NODE_") == -1:
                        
                        if connected_list[i]["scaffold"].find("NODE_") == -1:
                            closer_ref = connected_list[i]["scaffold"]
                            closer_ref_w = connected_list[i]["weight"]
                            level = str(counter_iterations) + "C" + str(i + 1) # first level is 1, not 0

                        elif connected_list[i]["assignment"].find("NODE_") == -1 and counter_iterations == 1:
                            continue # scaffold assigned are not considerated in the first iteration. This will skip the "break"

                        elif connected_list[i]["assignment"].find("NODE_") == -1:
                            closer_ref = connected_list[i]["assignment"]
                            closer_ref_w = connected_list[i]["weight"]
                            level = str(counter_iterations) + "C" + str(i + 1) # first level is 1, not 0
                        
                        # break the for-loop, because the first reference genome was reached
                        break
                        

                # if a reference genome was found within the connected-sameclustered:            
                if closer_ref != "n.a.": 
                    counter_new += 1

                    logging.info("VCSubcluster: %s" % (vc))
                    logging.info("closer_ref: %s" % closer_ref)
                    logging.info("closer_ref_w: %f" % closer_ref_w) 
                    logging.info("level: %s" % level)          

                    # update results
                    results = insertReference(df, results, scaffold, closer_ref, closer_ref_w, level, status, vc)
                    # upadate starting table and graph
                    scaffolds_ingraph.loc[scaffolds_ingraph["Genome"] == scaffold, ["Genome_editable"]] = closer_ref
                    g_copy.nodes[scaffold]['assignment'] = closer_ref
                
                
                else: # RETRY ITERATING THE WHOLE NEGHBORS 
                    
                    # associate every neighbors with its weight
                    connected_list = [] # this will be a list of DICT:
                    # {"scaffold": ___, "weight": ___, "assignment": ___}

                    for node in neighbors_list:
                        w = g_copy.get_edge_data(scaffold, node)["weight"]
                        assignment = g_copy.nodes[node]['assignment']
                        connected_list.append({"scaffold": node, "weight": w, "assignment": assignment})
                    # ordinate the list by weight (itemgetter is from the operator library)
                    connected_list = sorted(connected_list, key=itemgetter('weight'), reverse=True) # reverse for descending order
                    
                    
                    # 'CLOSER_REF' SEARCH
                    # iterate the list until the first reference genome is reached
                    for i in range(len(connected_list)):
                        if  connected_list[i]["scaffold"].find("NODE_") == -1 or connected_list[i]["assignment"].find("NODE_") == -1:

                            if connected_list[i]["scaffold"].find("NODE_") == -1:
                                closer_ref = connected_list[i]["scaffold"]
                                closer_ref_w = connected_list[i]["weight"]
                                level = str(counter_iterations) + "N" + str(i + 1) # first level is 1, not 0

                            elif connected_list[i]["assignment"].find("NODE_") == -1 and counter_iterations == 1:
                                continue # scaffold assigned are not considerated in the first iteration. This will skip the "break"
                            
                            elif connected_list[i]["assignment"].find("NODE_") == -1:
                                closer_ref = connected_list[i]["assignment"]
                                closer_ref_w = connected_list[i]["weight"]
                                level = str(counter_iterations) + "N" + str(i + 1) # first level is 1, not 0
                            
                            # break the for-loop, because the first reference genome was reached
                            break


                    # if a reference genome was found within the whole neighbors:                                 
                    if closer_ref != "n.a.": 
                        counter_new += 1
                        
                        logging.info("VCSubcluster: %s" % (vc))
                        logging.info("closer_ref: %s" % closer_ref)
                        logging.info("closer_ref_w: %f" % closer_ref_w) 
                        logging.info("level: %s" % level)          

                        # update results
                        results = insertReference(df, results, scaffold, closer_ref, closer_ref_w, level, status, vc)
                        # upadate starting table and graph
                        scaffolds_ingraph.loc[scaffolds_ingraph["Genome"] == scaffold, ["Genome_editable"]] = closer_ref
                        g_copy.nodes[scaffold]['assignment'] = closer_ref


                    else: # this means: NO reference in sameclustered AND NO reference in neighbors
                        logging.warning("Iteration %i: NO reference in connected sameclustered AND NO reference in neighbors." % counter_iterations)
               
            else: # "Singleton" never present in the graph
                logging.error("Found a strange VCStatus! Maybe it's a Singleton!")   

            logging.info("##############################################\n")

    # add the remaining scaffolds (level="F": present in the graph but not assigned)
    for row in scaffolds_ingraph.itertuples():
        if "NODE_" in row.Genome_editable:
            status = row.VCStatus # should NOT be a "Singleton", never present in the graph
            results = insertReference(df=df, results=results, scaffold=row.Genome_editable, closer="n.a.", weight="n.a.", level="F", status=status, vc="n.a.")

    logging.info('Processing of vConTACT2 output is ended.') 
    
    # order results by scaffold name
    results = results.sort_values(by=['Scaffold'])
    # convert results to a html table
    image_table = results.hvplot.table(width = 800, height = 200)
    # save results as a csv table
    results.to_csv(output_path + "results_vcontact2_" + string_suffix + ".csv")

    # save results as a MultiQC custom table
    content = textwrap.dedent("""
    # id: 'taxotab'
    # plot_type: 'table'
    # section_name: 'vConTACT2 taxonomy table'
    # description: 'Taxonomy table: automatic processing of vConTACT2 outputs `c1.ntw` and `genome_by_genome_overview.csv`.'
    <-- REPLACE -->
    """)
    string_eater = io.StringIO()
    datas = results.to_csv(path_or_buf = string_eater, sep='\t', index=False)
    content = content.replace("<-- REPLACE -->", string_eater.getvalue())
    file_report = open("custom_taxonomy_table_mqc.txt", "w")
    file_report.write(content)
    file_report.close()

    return image_table, results



def plotCreatorGraphvizHoloviews(g, df, results, output_path, string_suffix):

    # less problematic when called as variable
    df = df.rename(columns={"VC Subcluster": "VCSubcluster"})
    df = df.rename(columns={"VC Status": "VCStatus"})
    # sobstitute NA with '' to avoid future runtime errors
    df = df.fillna('')

    # create empty dict
    attribs = {}

    # for each row in df, preparate a col and a dict to rename nodes
    for index, row in df.iterrows():

        # not all references in genome_by_genome_overview.csv are contained in the graph
        if g.has_node(row.Genome) == False:
            continue

        # don't want to rename scaffold at this point
        if "NODE_" in row.Genome:
            # find the corresponding GenBank accession in the metadata table
            matches = results[results['Scaffold'] == row.Genome]
            if len(matches) != 1:
                # there should be only 1 exact match
                print("Strange things are happening!")
            else:
                # get first (and only) match
                match = matches.iloc[0]

                label= {"1 Closer": match.Closer,
                        "2 Accession": match.Accession,
                        "3 Status": match.Status,
                        "4 VC": match.VC,
                        "5 Level": match.Level,
                        "6 Weight": match.Weight,
                        "7 Genus": match.Genus,
                        "8 Family": match.Family,
                        "9 Host": match.Host}
                
                attribs[row.Genome] = label
                continue

        label= {"1 Species": row.Species,
                #"Accession": row.Accession,
                "2 Status": row.VCStatus,
                "3 VC": row.VCSubcluster,
                "4 Genus": row.Genus,
                "5 Family": row.Family,
                "6 Host": row.Host}

        attribs[row.Genome] = label

    # add attributes to nodes using the dict just prepared
    net.set_node_attributes(g, attribs)


    df_results_ingraph = deepcopy(results)
    df_results_assigned = deepcopy(results)
    df_results_confident = deepcopy(results)
    # subset results df: obtain scaffolds "assigned" and scaffolds "in-graph"
    # codes: not assigned ("F") or not-in-graph ("G")
    for row in results.itertuples():
        if row.Level == "F" or row.Level == "G": 
            df_results_assigned = df_results_assigned.drop(df_results_assigned[df_results_assigned.Scaffold == row.Scaffold].index)
            df_results_confident = df_results_confident.drop(df_results_confident[df_results_confident.Scaffold == row.Scaffold].index)
            if row.Level == "G":
                df_results_ingraph = df_results_ingraph.drop(df_results_ingraph[df_results_ingraph.Scaffold == row.Scaffold].index)
        elif not "1C" in row.Level:
            df_results_confident = df_results_confident.drop(df_results_confident[df_results_confident.Scaffold == row.Scaffold].index)


    # extract scaffold that are in-graph / that have received a taxanomy
    scaffolds_ingraph = df_results_ingraph['Scaffold'].tolist()
    scaffolds_assigned = df_results_assigned['Scaffold'].tolist()
    scaffolds_confident = df_results_confident['Scaffold'].tolist()
    

    # extract all nodes connected with "scaffolds_ingraph" nodes
    # with this strategy there will be much less nodes to render
    nodes_connected = []
    for element in scaffolds_ingraph:
        nodes_connected = nodes_connected + list(net.node_connected_component(g, element))
    nodes_connected = list(set(nodes_connected)) # remove duplicates if present
    
    connected_g = g.subgraph(nodes_connected) # create a sugraph for speeding up subsequent calcs
    
    # exclude scaffolds_assigned from the scoffolds_ingraph
    scaffolds_UNassigned = list(set(scaffolds_ingraph)-set(scaffolds_assigned))
    # exclude scaffolds from the reference genomes
    non_scaffolds = list(set(nodes_connected)-set(scaffolds_ingraph))
    
    # separate "assigneds" from "confidents" to avoid conflicts:
    scaffolds_assigned = list(set(scaffolds_assigned) - set(scaffolds_confident))

    # LABEL CREATION
    labels = df_results_confident['Closer'].tolist()
    # create dictionary for labels
    labdict = {}
    for i in range(len(scaffolds_confident)):
        labdict[scaffolds_confident[i]] = labels[i]


    # calculate position of  nodes
    # K: roughly corresponds to an ideal edge length (in inches). len can be used to override this value for adjacent nodes.
    # repulsiveforce: values larger than 1 tend to reduce the warping effect at the expense of less clustering.
    # overlap: determines if and how node overlaps should be removed. If "true" , overlaps are retained. 
    pos = graphviz_layout(connected_g, prog="sfdp",  args='-Goverlap=true')
    # note: sfdp requires graphviz built with gts, but this type of build is rarely available in conda
    # so sfdp will print "Error: remove_overlap: Graphviz not built with triangulation library"
    # right builds are graphviz==2.42.3=h055b950_2 and pygraphviz==1.6=py37hd4be98e_1 from conda-forge


    # PLOTTING as described in https://hvplot.holoviz.org/user_guide/NetworkX.html 
    # colors available at https://docs.bokeh.org/en/latest/docs/reference/colors.html 
    # in holoviews and in hvplot, the * operator superimposes the different layers of the plot
    # first of all, draw all the edges with the same style
    image = hvnx.draw_networkx_edges(connected_g, pos=pos, edge_width = 0.1, alpha = 0.3, width = 800, height = 500)
    # then draw the reference genomes 
    image = image * hvnx.draw_networkx_nodes(g.subgraph(non_scaffolds), pos=pos, node_color="aquamarine", node_size=200, alpha = 0.3, linewidths =0.0) 
    # draw scaffold not assigned
    image = image * hvnx.draw_networkx_nodes(g.subgraph(scaffolds_UNassigned), pos=pos, node_color="blue", node_size=200, alpha = 0.5, linewidths =0.0) 
    # draw assigned scaffolds with labels
    image = image * hvnx.draw_networkx_nodes(g.subgraph(scaffolds_assigned), pos=pos, node_color="orange", node_size=200, alpha = 0.5,  linewidths =0.0)
    image = image * hvnx.draw_networkx_nodes(g.subgraph(scaffolds_confident), pos=pos, node_color="red", node_size=200, alpha = 0.5,  linewidths =0.0, labels= labdict, font_size = "8pt")
    
    # save graph to html before returning it
    hvnx.save(image, "graph_layout.html")
    file = open("graph_layout.html", "r")
    line = file.read()
    file.close()
    line = textwrap.dedent("""
    <!--
    id: 'graphpane'
    section_name: 'vConTACT2 graph explorer'
    description: 'Interactive graph. Use buttons to interact. Hover nodes to see references.'
    -->
    """) + line
    file = open("custom_graph_plot_mqc.html", "w")
    file.write(line)
    file.close()
    return image


 
def filler(df, mt, output_path, string_suffix):

    # vConTACT2 used with the method described in https://github.com/RyanCook94/inphared.pl
    # produces a c1.ntw with GenBank accessions as node labels, and a genome_by_genome_overview.csv
    # with GenBank accessions as genome names. Moreover columns “Genus”, “Family” and “Order” 
    # are filled with "Unassigned" so they need to be filled with the correct taxonomy. 
    # Fortunately, method described at https://github.com/RyanCook94/inphared.pl provides a 
    # metadata table, 26Jan2021_data_excluding_refseq.tsv, containing the correct taxonomy for every GenBank accession. 

    # The following function update the void columns of genome_by_genome_overview.csv with the
    # taxonomies contained in 26Jan2021_data_excluding_refseq.tsv.

    # make editable copy
    df_edit = df.copy(deep=True) 

    # add some new columns
    df_edit["Accession"] = df_edit["Genome"] # copy to allow future edits of "Genome"
    df_edit["Host"] = None
    df_edit["FullClass"] = None
    df_edit["Species"] = None
    df_edit["Subfamily"] = None
    df_edit["Class"] = None
    df_edit["Phylum"] = None
    df_edit["Kingdom"] = None
    df_edit["Realm"] = None

    # for every row in df_edit:
    for index, row in df_edit.iterrows():
        
        # find the corresponding GenBank accession in the metadata table
        matches = mt[mt['Accession'] == row.Accession]
        if len(matches) == 0:
            # so this is a scaffold !
            pass
        elif (len(matches) != 0 and len(matches) != 1):
            # there should be only 1 exact match
            print("Strange things are happening!")
        else:
            # get first (and only) match
            match = matches.iloc[0]
            # fill df_edit with missing infos (Species, Genus, Family, Order, ...)
            df_edit.at[index,'Host'] = match.Host

            df_edit.at[index,'Species'] = match.Description
            df_edit.at[index,'Genus'] = match.Genus
            df_edit.at[index,'Family'] = match.Family

            # match.Classification is a big string like for example:
            # "Pseudomonas virus phiCTX Citexvirus Peduovirinae Myoviridae Caudovirales Caudoviricetes Uroviricota Heunggongvirae Duplodnaviria Viruses"
            # elaborate the string obtaining a vector of taxa ("species" excluded):
            linealogy = match.Classification.replace(match.Description + " ","").split(" ")
            
            try: # match.Classification is not always complete
                # access list in reverse order to keep distance from exceptions
                # -1 -> last. Useless in this case: it's always "Viruses"
                df_edit.at[index,'Realm'] = linealogy[-2] # -2 -> penultimate
                df_edit.at[index,'Kingdom'] = linealogy[-3] # -3 -> third last
                df_edit.at[index,'Phylum'] = linealogy[-4]
                df_edit.at[index,'Class'] = linealogy[-5]
                df_edit.at[index,'Order'] = linealogy[-6]
                df_edit.at[index,'Subfamily'] = linealogy[-8]
            except:
                pass

            df_edit.at[index,'FullClass'] = match.Classification

    return df_edit




if __name__ == "__main__":

    terminal_mode = True
    if not terminal_mode:
        sys.argv = ['graph_analyzer.py', 
                '--input-graph', './inputs/new_vcontact2/c1.ntw',
                '--input-csv', './inputs/new_vcontact2/genome_by_genome_overview.csv', 
                '--input-metas', './inputs/new_vcontact2/26Jan2021_data_excluding_refseq.tsv',
                '--output', './outputs/',
                '--suffix', 'newvcon']
    parameters = parser.parse_args()


    with open(parameters.input_graph, 'r') as graph_table ,  open(parameters.input_csv, 'r') as csv_table:
        
        """
        from: https://networkx.github.io/documentation/stable/reference/classes/index.html#which-graph-class-should-i-use
        Networkx Class      Type            Self-loops allowed      Parallel edges allowed
        Graph               undirected      Yes                     No
        DiGraph             directed        Yes                     No
        MultiGraph          undirected      Yes                     Yes
        MultiDiGraph        directed        Yes                     Yes
        """

        # the total graph, usually opened with Cytoscape
        g = net.read_edgelist(graph_table, nodetype=str, data=(('weight',float),), create_using=net.Graph())

        # the table that specifies cluster divisions
        df = pnd.read_csv(csv_table, header = 0)

        # the table linking GenBank accession with its taxonomy
        if parameters.input_metas != None:
            metas_table = open(parameters.input_metas, 'r')
            mt = pnd.read_csv(metas_table, header = 0, sep='\t')
            df = filler(df, mt, parameters.output_path, parameters.string_suffix)

        # for every viral scaffold, get the most probable taxonomy 
        image_table, df_results = clusterExtractor(g, df, parameters.output_path, parameters.string_suffix)
        
        # generate a general plot with all reference genomes and viral scaffolds
        image_graph = plotCreatorGraphvizHoloviews(g, df, df_results, parameters.output_path, parameters.string_suffix) 

        # MAKING OF THE PANEL APP (https://holoviz.org/tutorial/Building_Panels.html)
        # pane: view of an external object (text, image, plot, etc.) by wrapping it
        # panel: lays out multiple components in a row, column, or grid
        # widget: provides input controls to add interactive features to the panel
        title_pane = pnl.panel('<h1 style="text-align: center;"> ' + parameters.string_suffix + ' graph panel </h1>', width=800)
        graph_pane = pnl.panel(image_graph) # returns a HoloViews(Overlay)
        table_pane = pnl.panel(image_table) # returns a HoloViews(Table)
        columnar_panel = pnl.Column(title_pane, graph_pane, table_pane)
        columnar_panel.save(parameters.output_path + 'panel_graph_' + parameters.string_suffix + '.html', resources=INLINE)